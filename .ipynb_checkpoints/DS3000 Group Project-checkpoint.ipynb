{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold, cross_validate)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Suppress overflow warnings from sklearn/numpy\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "np.seterr(over='ignore')\n",
    "\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "\n",
    "#Check device for NN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eccb276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ECGCvdata 2.csv') #replace obv\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0db8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5817f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ab7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noticing a lot of NULLS with some entries not having complete data, we will see how valid those stats are \n",
    "# And decide if we are able to drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Drop columns with >50% missing\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "high_missing_cols = missing_pct[missing_pct > 50].index.tolist()\n",
    "df_clean = df.drop(columns=high_missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers \n",
    "num_features = df.select_dtypes(include='number').columns\n",
    "outliers_list = []\n",
    "\n",
    "for col in num_features:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    median = df[col].median()\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - (1.5 * IQR)\n",
    "    upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    outliers_list.append([col, len(outliers)])\n",
    "\n",
    "for col_name, outlier_count in outliers_list:\n",
    "    print(f\"{col_name}: {outlier_count} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e121b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With these results its clear we should fill NaNs with median not mean\n",
    "\n",
    "# Fill NaNs left with median\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d46553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show different results for ECG_signal\n",
    "print(sorted(df['ECG_signal'].unique().tolist()))\n",
    "# AFF = Atrial Fibrillation: Rapid irregular atrial activity\n",
    "# ARR = Arrhythmia: Abnormal Rhytms aren't speficially labeled\n",
    "# CHF = Congestive Heart Failure: Not rhytm but heart fail;ure\n",
    "# NSR = Normal Sinus Rhythm: healthy regular heartbeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_encoded = pd.get_dummies(df, columns=['ECG_signal'], dtype=int)\n",
    "df_encoded.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcdc44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e161af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['RRmean', 'PPmean', 'RTdis', 'PonTdis', 'PonToffdis', 'QTdis',\n",
    "                'IBIM', 'NN50', 'hbpermin', 'RSslope', 'RRTot', 'NNTot', 'STslope']\n",
    "\n",
    "feature_list = [c for c in feature_list if c in df_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression R^2 for EACH class (using your feature_list)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_encoded[feature_list]\n",
    "label_cols = [c for c in df_encoded.columns if c.startswith('ECG_signal_')]\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "r2_table = []\n",
    "\n",
    "for lab in label_cols:\n",
    "    y = df_encoded[lab].astype(float)\n",
    "    mask = y.notna()               # (y should be clean, but keep it consistent)\n",
    "    X_use = X.loc[mask]\n",
    "    y_use = y.loc[mask]\n",
    "    if y_use.nunique() <= 1:       # constant target => R² undefined\n",
    "        r2 = np.nan\n",
    "    else:\n",
    "        pipe.fit(X_use, y_use)\n",
    "        r2 = pipe.score(X_use, y_use)\n",
    "    r2_table.append((lab, r2))\n",
    "\n",
    "# Show R^2 sorted (highest first)\n",
    "r2_table = sorted(r2_table, key=lambda x: x[1], reverse=True)\n",
    "r2_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can tell the regular one is MUCH higher than the rest.\n",
    "# Adding a proper classifier + CV AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which features were dropped and which remain\n",
    "set(['RRmean','PPmean','RTdis','PonTdis','PonToffdis','QTdis','IBIM','NN50','hbpermin','RSslope','RRTot','NNTot','STslope']) - set(df_encoded.columns)\n",
    "\n",
    "# Confirm X is clean *after* imputation is applied in the pipeline (no need to impute here)\n",
    "df_encoded[feature_list].isna().sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Check label balance\n",
    "df_encoded[label_cols].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed59b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations among features\n",
    "corr_matrix = df_encoded[feature_list].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs (>0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "print(\"Highly correlated features (>0.9):\")\n",
    "for feat1, feat2, corr in high_corr:\n",
    "    print(f\"{feat1} <-> {feat2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping PPmean as same hting as RRMean\n",
    "features_final = [f for f in feature_list if f not in ['PPmean',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlations among features\n",
    "corr_matrix = df_encoded[features_final].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs (>0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "print(\"Highly correlated features (>0.9):\")\n",
    "for feat1, feat2, corr in high_corr:\n",
    "    print(f\"{feat1} <-> {feat2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4af6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test Split\n",
    "\n",
    "X = df_encoded[features_final]\n",
    "y = df_encoded[label_cols].values\n",
    "\n",
    "y_labels = df_encoded[label_cols].idxmax(axis=1).str.replace('ECG_Signal_','')\n",
    "\n",
    "# Spliting: 60% train, 20% val, 20% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_labels, test_size=0.4, stratify=y_labels, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(f\"Train distribution:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c52aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One note is that RRmean and PPmean being 1 is not a red flag, but should not be used \n",
    "# To train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9692c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation HELPER function to give accuracy for P/R/F1 scores -> Useful for model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, pipeline, X_tr, y_tr, X_va, y_va):\n",
    "    pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "    # Predictions\n",
    "    y_tr_pred = pipeline.predict(X_tr)\n",
    "    y_va_pred = pipeline.predict(X_va)\n",
    "\n",
    "    # Accuracy\n",
    "    acc_tr = accuracy_score(y_tr, y_tr_pred)\n",
    "    acc_va = accuracy_score(y_va, y_va_pred)\n",
    "\n",
    "    # Macro P/R/F1 (Equally weighted)\n",
    "    p_va, r_va, f1_va, _ = precision_recall_fscore_support(\n",
    "        y_va, y_va_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Weighted P/R/F1 (accounts for class support)\n",
    "    p_weighted, r_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_va, y_va_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Train accuracy: {acc_tr:.3f}\")\n",
    "    print(f\"Val accuracy:   {acc_va:.3f}\")\n",
    "    print(f\"Val macro P/R/F1: {p_va:.3f} / {r_va:.3f} / {f1_va:.3f}\")\n",
    "    print(f\"Val weighted P/R/F1: {p_weighted: .3f} / {r_weighted:.3f} / {f1_weighted:.3f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    labels_sorted = sorted(y_va.unique())\n",
    "    print(\"Labels order:\", labels_sorted)\n",
    "    print(\"Val confusion matrix:\\n\",\n",
    "          confusion_matrix(y_va, y_va_pred, labels=labels_sorted))\n",
    "    \n",
    "    print(\"\\nPer-class classification report:\\n\",\n",
    "          classification_report(y_va, y_va_pred, digits=3, zero_division=0))\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "# Logistic Regression baseline linear classifer\n",
    "# Classic ML baseline, imputation + standardization\n",
    "\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter = 1000,\n",
    "        multi_class = 'multinomial'\n",
    "    ))\n",
    "])\n",
    "\n",
    "log_reg_pipeline = evaluate_model(\n",
    "    \"Logistic Regression\",\n",
    "    log_reg_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpreting the confusion matrix \n",
    "# 60 Sampels per class in validation (240 total)\n",
    "# AFF: 48/60 correct (80%)\n",
    "# ARR: 60/60 correct (100%)\n",
    "# CHF: 57/60 correct (95%)\n",
    "# NSR: 60/60 correct (100%)\n",
    "\n",
    "# Not bad, but when it coems to life-or-death situations we don't want any level of risk\n",
    "# Let's see if we can do better\n",
    "\n",
    "\n",
    "## Note\n",
    "#the linear model is unable to reliably distinguish between AFF and CHF, misclassifying 20% of AFF cases??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0fa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "\n",
    "rf_pipeline = Pipeline ([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    # No scaler needed for trees\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_pipeline = evaluate_model(\n",
    "    \"Random Forest\",\n",
    "    rf_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN\n",
    "def build_knn_pipeline(k):\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=k))\n",
    "    ])\n",
    "\n",
    "ks = [3, 5, 7, 9]\n",
    "knn_results = {}\n",
    "\n",
    "for k in ks:\n",
    "    pipe = build_knn_pipeline(k)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_val_pred = pipe.predict(X_val)\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_val, y_val_pred, average='macro'\n",
    "    )\n",
    "    knn_results[k] = (acc, p, r, f1)\n",
    "\n",
    "print(\"k-NN validation results:\")\n",
    "for k, (acc, p, r, f1) in knn_results.items():\n",
    "    print(f\"k={k}: acc={acc:.3f}, macro F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this validaiton score we can select k=3 being the most precise model \n",
    "best_k = max(knn_results, key=lambda k: knn_results[k][0])\n",
    "print(\"Best k on validation:\", best_k)\n",
    "\n",
    "knn_best_pipeline = build_knn_pipeline(best_k)\n",
    "knn_best_pipeline = evaluate_model(\n",
    "    f\"k-NN (k={best_k})\",\n",
    "    knn_best_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With this model we can see eventhough we have a very high train and val accuracy we can see 5 FN precditions\n",
    "# With 5 (True AFF, predicted CHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "dt_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('clf', DecisionTreeClassifier(\n",
    "        max_depth=6, # Adjust this??? None = Full-depth will overfit\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "dt_pipeline= evaluate_model(\n",
    "    \"Decision Tree (max_depth=6)\",\n",
    "    dt_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595368f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Showcasing overfitting for Decision Tree\n",
    "dt_overfit_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('clf', DecisionTreeClassifier(\n",
    "        max_depth=None,   # let it grow fully\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "dt_overfit_pipeline = evaluate_model(\n",
    "    \"Decision Tree (max_depth=None)\",\n",
    "    dt_overfit_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e38988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('clf', GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "gb_pipeline=evaluate_model(\n",
    "    \"Gradient Boosting\",\n",
    "    gb_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold stratified CV \n",
    "\n",
    "X_all = df_encoded[features_final]\n",
    "y_all = y_labels \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models as pipelines (imputer + optional scaler + classifier)\n",
    "models = {\n",
    "    \"LogisticRegression\": log_reg_pipeline,\n",
    "    \"RandomForestClassifier\": rf_pipeline,\n",
    "    \"KNeighbourClassifier\": knn_best_pipeline, # k=3\n",
    "    \"DecisionTreeClassifier\": dt_pipeline,\n",
    "    \"GradientBoostingClassifier\": gb_pipeline,\n",
    "}\n",
    "\n",
    "# Run CV and collect macro P/R/F1 for each model\n",
    "results = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    cv_scores = cross_validate(\n",
    "        pipe, X_all, y_all, cv=skf,\n",
    "        scoring=['precision_macro', 'recall_macro', 'f1_macro']\n",
    "    )\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": cv_scores['test_precision_macro'].mean() * 100,\n",
    "        \"Recall\":    cv_scores['test_recall_macro'].mean() * 100,\n",
    "        \"F1 Score\":  cv_scores['test_f1_macro'].mean() * 100\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca71483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "order = results_df.sort_values('Recall', ascending=False)['Model']\n",
    "\n",
    "# Long format for seaborn\n",
    "results_long = results_df.melt(\n",
    "    id_vars='Model',\n",
    "    value_vars=['Precision', 'Recall', 'F1 Score'],\n",
    "    var_name='Metric',\n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(\n",
    "    data=results_long,\n",
    "    x='Model',\n",
    "    y='Score',\n",
    "    hue='Metric',\n",
    "    order=order\n",
    ")\n",
    "\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Model Name')\n",
    "plt.title('Model Performance Metrics (5-fold CV, Macro Averages)\\nSorted by Recall')\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.legend(title='Metric')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39082fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regularized Neural Network (fixed)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "imputer = SimpleImputer(strategy='ßmedian')\n",
    "X_imputed = imputer.fit_transform(df_encoded[features_final])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "\n",
    "y_indices = df_encoded[label_cols].values.argmax(axis=1)\n",
    "\n",
    "# resplitting (run independend)\n",
    "X_tr, X_temp, y_tr, y_temp = train_test_split(\n",
    "    X_scaled, y_indices,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_indices\n",
    ")\n",
    "X_va, X_te, y_va, y_te = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "train_data = TensorDataset(torch.FloatTensor(X_tr), torch.LongTensor(y_tr))\n",
    "val_data   = TensorDataset(torch.FloatTensor(X_va), torch.LongTensor(y_va))\n",
    "test_data  = TensorDataset(torch.FloatTensor(X_te), torch.LongTensor(y_te))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#regularization\n",
    "class ECGClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ECGClassifier, self).__init__()\n",
    "\n",
    "        self.layer1   = nn.Linear(input_dim, 64)\n",
    "        self.bn1      = nn.BatchNorm1d(64)\n",
    "        self.relu     = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.4)    \n",
    "\n",
    "        self.layer2   = nn.Linear(64, 32)\n",
    "        self.bn2      = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.3)     \n",
    "        self.output   = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "input_dim   = X_tr.shape[1]\n",
    "num_classes = len(label_cols)  # 4\n",
    "model = ECGClassifier(input_dim, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4      \n",
    ")\n",
    "\n",
    "num_epochs    = 100\n",
    "best_val_loss = float('inf')\n",
    "patience      = 10\n",
    "trigger_times = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "\n",
    "best_state_dict = None  \n",
    "\n",
    "print(\"Starting Neural Network Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss   = val_loss / len(val_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss  = avg_val_loss\n",
    "        trigger_times  = 0\n",
    "        best_state_dict = model.state_dict() \n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)\n",
    "else:\n",
    "    print(\"WARNING: FileNotFoundError\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs        = model(inputs)\n",
    "        _, predicted   = torch.max(outputs, 1)\n",
    "\n",
    "        y_true_test.extend(labels.cpu().numpy())\n",
    "        y_pred_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(\"\\n=== Neural Network Final Test Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(\n",
    "          y_true_test,\n",
    "          y_pred_test,\n",
    "          target_names=label_cols \n",
    "      ))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Neural Network Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e19147",
   "metadata": {},
   "source": [
    "Moral of the story neural network not needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold stratified CV including Neural Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Prepare data\n",
    "X_all = df_encoded[features_final]\n",
    "y_all = y_labels \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models as pipelines (imputer + optional scaler + classifier)\n",
    "models = {\n",
    "    \"LogisticRegression\": log_reg_pipeline,\n",
    "    \"RandomForestClassifier\": rf_pipeline,\n",
    "    \"KNeighbourClassifier\": knn_best_pipeline,\n",
    "    \"DecisionTreeClassifier\": dt_pipeline,\n",
    "    \"GradientBoostingClassifier\": gb_pipeline,\n",
    "}\n",
    "\n",
    "# Run CV for traditional models\n",
    "results = []\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    cv_scores = cross_validate(\n",
    "        pipe, X_all, y_all, cv=skf,\n",
    "        scoring=['precision_macro', 'recall_macro', 'f1_macro']\n",
    "    )\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Precision\": cv_scores['test_precision_macro'].mean() * 100,\n",
    "        \"Recall\":    cv_scores['test_recall_macro'].mean() * 100,\n",
    "        \"F1 Score\":  cv_scores['test_f1_macro'].mean() * 100\n",
    "    })\n",
    "\n",
    "# Neural Network CV (manual implementation)\n",
    "print(\"Running Neural Network 5-fold CV...\")\n",
    "\n",
    "# Impute and scale all data first\n",
    "imputer_cv = SimpleImputer(strategy='median')\n",
    "X_imputed_cv = imputer_cv.fit_transform(X_all)\n",
    "scaler_cv = StandardScaler()\n",
    "X_scaled_cv = scaler_cv.fit_transform(X_imputed_cv)\n",
    "\n",
    "# Convert labels to indices\n",
    "y_indices_cv = df_encoded[label_cols].values.argmax(axis=1)\n",
    "\n",
    "nn_precisions = []\n",
    "nn_recalls = []\n",
    "nn_f1s = []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_scaled_cv, y_indices_cv)):\n",
    "    print(f\"  Fold {fold_idx + 1}/5\", end='... ')\n",
    "    \n",
    "    # Split data\n",
    "    X_tr_fold = X_scaled_cv[train_idx]\n",
    "    y_tr_fold = y_indices_cv[train_idx]\n",
    "    X_va_fold = X_scaled_cv[val_idx]\n",
    "    y_va_fold = y_indices_cv[val_idx]\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_data_fold = TensorDataset(torch.FloatTensor(X_tr_fold), torch.LongTensor(y_tr_fold))\n",
    "    val_data_fold = TensorDataset(torch.FloatTensor(X_va_fold), torch.LongTensor(y_va_fold))\n",
    "    \n",
    "    train_loader_fold = DataLoader(train_data_fold, batch_size=32, shuffle=True)\n",
    "    val_loader_fold = DataLoader(val_data_fold, batch_size=32)\n",
    "    \n",
    "    # Initialize model\n",
    "    model_fold = ECGClassifier(X_tr_fold.shape[1], len(label_cols)).to(device)\n",
    "    criterion_fold = nn.CrossEntropyLoss()\n",
    "    optimizer_fold = optim.Adam(model_fold.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    # Training\n",
    "    best_val_loss_fold = float('inf')\n",
    "    patience_fold = 10\n",
    "    trigger_times_fold = 0\n",
    "    best_state_dict_fold = None\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        model_fold.train()\n",
    "        for inputs, labels in train_loader_fold:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer_fold.zero_grad()\n",
    "            outputs = model_fold(inputs)\n",
    "            loss = criterion_fold(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_fold.step()\n",
    "        \n",
    "        # Validation\n",
    "        model_fold.eval()\n",
    "        val_loss_fold = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader_fold:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model_fold(inputs)\n",
    "                loss = criterion_fold(outputs, labels)\n",
    "                val_loss_fold += loss.item()\n",
    "        \n",
    "        avg_val_loss_fold = val_loss_fold / len(val_loader_fold)\n",
    "        \n",
    "        if avg_val_loss_fold < best_val_loss_fold:\n",
    "            best_val_loss_fold = avg_val_loss_fold\n",
    "            trigger_times_fold = 0\n",
    "            best_state_dict_fold = model_fold.state_dict()\n",
    "        else:\n",
    "            trigger_times_fold += 1\n",
    "            if trigger_times_fold >= patience_fold:\n",
    "                break\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    if best_state_dict_fold is not None:\n",
    "        model_fold.load_state_dict(best_state_dict_fold)\n",
    "    \n",
    "    model_fold.eval()\n",
    "    y_true_fold = []\n",
    "    y_pred_fold = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader_fold:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_fold(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true_fold.extend(labels.cpu().numpy())\n",
    "            y_pred_fold.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true_fold, y_pred_fold, average='macro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    nn_precisions.append(p * 100)\n",
    "    nn_recalls.append(r * 100)\n",
    "    nn_f1s.append(f1 * 100)\n",
    "    \n",
    "    print(f\"P: {p*100:.2f}%, R: {r*100:.2f}%, F1: {f1*100:.2f}%\")\n",
    "\n",
    "# Add NN results\n",
    "results.append({\n",
    "    \"Model\": \"NeuralNetwork\",\n",
    "    \"Precision\": np.mean(nn_precisions),\n",
    "    \"Recall\": np.mean(nn_recalls),\n",
    "    \"F1 Score\": np.mean(nn_f1s)\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== 5-Fold CV Results (All Models) ===\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualization\n",
    "order = results_df.sort_values('Recall', ascending=False)['Model']\n",
    "\n",
    "results_long = results_df.melt(\n",
    "    id_vars='Model',\n",
    "    value_vars=['Precision', 'Recall', 'F1 Score'],\n",
    "    var_name='Metric',\n",
    "    value_name='Score'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    data=results_long,\n",
    "    x='Model',\n",
    "    y='Score',\n",
    "    hue='Metric',\n",
    "    order=order\n",
    ")\n",
    "\n",
    "plt.ylabel('Percentage %')\n",
    "plt.xlabel('Model Name')\n",
    "plt.title('Model Performance Metrics (5-fold CV, Macro Averages)\\nSorted by Recall')\n",
    "plt.ylim(90, 100)  # Adjusted to better show differences\n",
    "plt.xticks(rotation=25, ha='right')\n",
    "plt.legend(title='Metric')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DS3000env)",
   "language": "python",
   "name": "ds3000env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
